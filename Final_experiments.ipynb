{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91f70436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b039a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea360a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scaling the input\n",
    "'''\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "scaler=sc.fit(users)  #train_new[['Average_Users']]\n",
    "train_scaled = scaler.transform(users)  \n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b02f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create input output for deep learning models\n",
    "def create_data(n_future, n_past, train_scaled):\n",
    "    trainX=[] #input\n",
    "    trainY=[] #prediction\n",
    "    for i in range(n_past,len(train_scaled)-n_future+1):\n",
    "        trainX.append(train_scaled[i-n_past:i,0:train_scaled.shape[1]])\n",
    "        trainY.append(train_scaled[i+n_future-1:i+n_future,0])\n",
    "    trainX,trainY=np.array(trainX),np.array(trainY)\n",
    "    return trainX, trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ff5405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for train-test-split\n",
    "#Train test split 90-10\n",
    "def train_test(percentage,dataX,dataY):\n",
    "    ind = int(percentage * len(dataX))\n",
    "    x_tr = dataX[:ind]\n",
    "    y_tr = dataY[:ind]\n",
    "    x_val = dataX[ind:]\n",
    "    y_val= dataY[ind:]\n",
    "    return x_tr,y_tr,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e634e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile\n",
    "def model_compile(m,x_train,y_train,x_validate,y_validate,epoch,batch):\n",
    "    m.compile(loss='mse',optimizer='adam')\n",
    "    #Define the callback to save the best model during the training\n",
    "    #mc = ModelCheckpoint('../out/best_model.hdf5', monitor='val_loss',verbose=1, save_best_only=True, mode='min')\n",
    "    early_stopping_monitor = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0,\n",
    "        patience=0,\n",
    "        verbose=0,\n",
    "        mode='auto',\n",
    "        baseline=None,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    # Train the model for 30 epochs with batch size of 32:\n",
    "    history=m.fit(x_train, y_train ,epochs=epoch, batch_size=batch, validation_data=(x_validate,y_validate), callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7bafc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict and inverse transform\n",
    "def predict_inverse(model,train,validation_x,sc):\n",
    "    forecast=model.predict(validation_x)\n",
    "    y_pred_future=sc.inverse_transform(forecast)\n",
    "    y_actual=train.loc[len(train)-forecast.shape[0]:,'Average_Users']\n",
    "    y_pred=[float(i) for i in y_pred_future]\n",
    "    y_actual=[i for i in y_actual.values]\n",
    "    df = pd.DataFrame(list(zip(y_pred, y_actual)),columns =['Predicted', 'Actual'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d1d5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6c50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_pred-y_true)**2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a12892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steps\n",
    "#Read data, transform, create X,y\n",
    "#Split into train test\n",
    "#Build and compile model,\n",
    "#Fit data\n",
    "#Predict for validation\n",
    "#compute evaluation metrics on validation data\n",
    "import random\n",
    "random.seed(42)\n",
    "train=pd.read_csv('../out/Univariate_Wikipedia.csv')\n",
    "train['Date']=pd.to_datetime(train['Date'])\n",
    "train_df=train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d0c258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Average_Users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-07-01</td>\n",
       "      <td>1024.882127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-07-02</td>\n",
       "      <td>1031.233602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-07-03</td>\n",
       "      <td>973.123388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-07-04</td>\n",
       "      <td>1003.791022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-07-05</td>\n",
       "      <td>1044.341920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Average_Users\n",
       "0 2015-07-01    1024.882127\n",
       "1 2015-07-02    1031.233602\n",
       "2 2015-07-03     973.123388\n",
       "3 2015-07-04    1003.791022\n",
       "4 2015-07-05    1044.341920"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb9f1ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/31 [==============================] - 4s 26ms/step - loss: 0.0548 - val_loss: 0.0178\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0172 - val_loss: 0.0160\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0101\n",
      "Epoch 6/30\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "scaler=sc.fit(train_df[['Average_Users']])  #\n",
    "scaled_data1 = scaler.transform(train_df[['Average_Users']]) \n",
    "X1,Y1=create_data(1, 2, scaled_data1)\n",
    "x_tr1,y_tr1,x_val1,y_val1=train_test(0.90,X1,Y1)\n",
    "# define model 1\n",
    "model1 =  Sequential()\n",
    "model1.add(LSTM(128,activation='relu',input_shape=(x_tr1.shape[1],x_tr1.shape[2]),return_sequences=True))\n",
    "model1.add(Dense(64,activation='relu'))\n",
    "model1.add(Dense(1,activation='linear'))\n",
    "#model1.summary()\n",
    "#compile model1\n",
    "model_compile(model1,x_tr1,y_tr1,x_val1,y_val1,30,16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eca64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b0b4a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010114029981195927"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_val1,y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "311d5192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast1=model1.predict(x_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8813167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = forecast1.shape\n",
    "forecast = forecast1.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce771da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future=sc.inverse_transform(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "056fbec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90101a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for LSTM =  5.907143377972659\n"
     ]
    }
   ],
   "source": [
    "y_actual=train_df.loc[len(train_df)-forecast1.shape[0]:,'Average_Users']\n",
    "y_pred=[float(sum(i))/2 for i in y_pred_future]\n",
    "y_actual=[i for i in y_actual.values]\n",
    "df1 = pd.DataFrame(list(zip(y_pred, y_actual)),columns =['Predicted', 'Actual'])\n",
    "\n",
    "print('MAPE for LSTM = ',mape(df1['Actual'], df1['Predicted']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d515a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for LSTM =  15358.371555816706\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#df1.head()\n",
    "print('MSE for LSTM = ',mse(df1['Actual'], df1['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d42df4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked LSTM\n",
    "# define model\n",
    "sc = MinMaxScaler()\n",
    "scaler=sc.fit(train_df[['Average_Users']])  #\n",
    "scaled_data2 = scaler.transform(train_df[['Average_Users']]) \n",
    "X2,Y2=create_data(1, 2, scaled_data2)\n",
    "x_tr2,y_tr2,x_val2,y_val2=train_test(0.90,X2,Y2)\n",
    "model2 =  Sequential()\n",
    "model2.add(LSTM(128,activation='relu',input_shape=(x_tr2.shape[1],x_tr2.shape[2]),return_sequences=True))\n",
    "model2.add(LSTM(64,activation='relu',return_sequences=True))\n",
    "model2.add(LSTM(32,activation='relu',return_sequences=False))\n",
    "model2.add(Dense(32,activation='relu'))\n",
    "model2.add(Dense(1,activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19f14580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 2, 128)            66560     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 2, 64)             49408     \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129473 (505.75 KB)\n",
      "Trainable params: 129473 (505.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 9s 28ms/step - loss: 0.0953 - val_loss: 0.0884\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0292 - val_loss: 0.0164\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.0133\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 5/30\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0157\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n",
    "model_compile(model2,x_tr2,y_tr2,x_val2,y_val2,30,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de3d6a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast2=model2.predict(x_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "678175aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54675d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future=sc.inverse_transform(forecast2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c5a20da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for Stacked LSTM =  6.401187486266502\n"
     ]
    }
   ],
   "source": [
    "y_actual=train_df.loc[len(train_df)-forecast2.shape[0]:,'Average_Users']\n",
    "y_pred=[float(i) for i in y_pred_future]\n",
    "y_actual=[i for i in y_actual.values]\n",
    "df2 = pd.DataFrame(list(zip(y_pred, y_actual)),columns =['Predicted', 'Actual'])\n",
    "\n",
    "print('MAPE for Stacked LSTM = ',mape(df2['Actual'], df2['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d29cb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Stacked LSTM =  19441.96353736812\n"
     ]
    }
   ],
   "source": [
    "print('MSE for Stacked LSTM = ',mse(df2['Actual'], df2['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee96b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (None, 2, 128)            50304     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2, 64)             8256      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2, 1)              65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58625 (229.00 KB)\n",
      "Trainable params: 58625 (229.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 6s 36ms/step - loss: 0.0355 - val_loss: 0.0166\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0083 - val_loss: 0.0100\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0106\n"
     ]
    }
   ],
   "source": [
    "#GRU\n",
    "sc = MinMaxScaler()\n",
    "scaler=sc.fit(train_df[['Average_Users']])  #\n",
    "scaled_data3 = scaler.transform(train_df[['Average_Users']]) \n",
    "X3,Y3=create_data(1, 2, scaled_data3)\n",
    "x_tr3,y_tr3,x_val3,y_val3=train_test(0.90,X3,Y3)\n",
    "model3=Sequential()\n",
    "model3.add(GRU(128,activation='tanh',input_shape=(x_tr3.shape[1],x_tr3.shape[2]),return_sequences=True))\n",
    "model3.add(Dense(64,activation='relu'))\n",
    "model3.add(Dense(1,activation='linear'))\n",
    "model3.summary()\n",
    "model_compile(model3,x_tr3,y_tr3,x_val3,y_val3,30,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5de40106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 0s/step\n"
     ]
    }
   ],
   "source": [
    "forecast3=model3.predict(x_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0083a5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 2, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc7681f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = forecast3.shape\n",
    "forecastnew = forecast3.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c15bc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future=sc.inverse_transform(forecastnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e918b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for GRU =  5.97025980140007\n"
     ]
    }
   ],
   "source": [
    "y_actual=train_df.loc[len(train_df)-forecastnew.shape[0]:,'Average_Users']\n",
    "y_pred=[float(sum(i))/2 for i in y_pred_future]\n",
    "y_actual=[i for i in y_actual.values]\n",
    "df3 = pd.DataFrame(list(zip(y_pred, y_actual)),columns =['Predicted', 'Actual'])\n",
    "\n",
    "print('MAPE for GRU = ',mape(df3['Actual'], df3['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c49f38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for GRU =  14757.255738758653\n"
     ]
    }
   ],
   "source": [
    "print('MSE for GRU = ',mse(df3['Actual'], df3['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "455af1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked GRU\n",
    "sc = MinMaxScaler()\n",
    "scaler=sc.fit(train_df[['Average_Users']])  #\n",
    "scaled_data4 = scaler.transform(train_df[['Average_Users']]) \n",
    "X4,Y4=create_data(1, 2, scaled_data4)\n",
    "x_tr4,y_tr4,x_val4,y_val4=train_test(0.90,X4,Y4)\n",
    "model4=Sequential()\n",
    "model4.add(GRU(128,activation='tanh',input_shape=(x_tr4.shape[1],x_tr4.shape[2]),return_sequences=True))\n",
    "model4.add(GRU(64,activation='tanh',input_shape=(x_tr4.shape[1],x_tr4.shape[2]),return_sequences=True))\n",
    "model4.add(GRU(32,activation='tanh',input_shape=(x_tr4.shape[1],x_tr4.shape[2]),return_sequences=False))\n",
    "model4.add(Dense(64,activation='relu'))\n",
    "model4.add(Dense(1,activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7374755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_1 (GRU)                 (None, 2, 128)            50304     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 2, 64)             37248     \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 32)                9408      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99137 (387.25 KB)\n",
      "Trainable params: 99137 (387.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "31/31 [==============================] - 15s 62ms/step - loss: 0.0375 - val_loss: 0.0266\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0058 - val_loss: 0.0096\n",
      "Epoch 4/30\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0060 - val_loss: 0.0098\n"
     ]
    }
   ],
   "source": [
    "model4.summary()\n",
    "model_compile(model4,x_tr4,y_tr4,x_val4,y_val4,30,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4539286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000240DBDDFE20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast4=model4.predict(x_val4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c20d532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ff5ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future=sc.inverse_transform(forecast4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b6ab2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for Stacked GRU =  6.3279812864464295\n"
     ]
    }
   ],
   "source": [
    "y_actual=train_df.loc[len(train_df)-forecast4.shape[0]:,'Average_Users']\n",
    "y_pred=[float(i) for i in y_pred_future]\n",
    "y_actual=[i for i in y_actual.values]\n",
    "df4 = pd.DataFrame(list(zip(y_pred, y_actual)),columns =['Predicted', 'Actual'])\n",
    "\n",
    "print('MAPE for Stacked GRU = ',mape(df4['Actual'], df4['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea9c8139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Stacked GRU =  16439.137253628924\n"
     ]
    }
   ],
   "source": [
    "print('MSE for Stacked GRU = ',mse(df4['Actual'], df4['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c662b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilstm\n",
    "sc = MinMaxScaler()\n",
    "scaler=sc.fit(train_df[['Average_Users']])  #\n",
    "scaled_data5 = scaler.transform(train_df[['Average_Users']]) \n",
    "X5,Y5=create_data(1, 2, scaled_data5)\n",
    "x_tr5,y_tr5,x_val5,y_val5=train_test(0.90,X5,Y5)\n",
    "model5=Sequential()\n",
    "model5.add(Bidirectional(LSTM(128,activation='relu',input_shape=(x_tr5.shape[1],x_tr5.shape[2]),return_sequences=True)))\n",
    "model5.add(Bidirectional(LSTM(32,activation='relu',return_sequences=False)))\n",
    "model5.add(Dense(64,activation='relu'))\n",
    "model5.add(Dense(1,activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f95c38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/31 [==============================] - 12s 53ms/step - loss: 0.0727 - val_loss: 0.0108\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0138 - val_loss: 0.0087\n",
      "Epoch 3/30\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0073 - val_loss: 0.0091\n"
     ]
    }
   ],
   "source": [
    "#model5.summary()\n",
    "model_compile(model5,x_tr5,y_tr5,x_val5,y_val5,30,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aab01066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000240E6D3BD80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast5=model5.predict(x_val5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0100f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "343f3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future=sc.inverse_transform(forecast5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1daa3739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for BiLSTM =  5.250967303795877\n"
     ]
    }
   ],
   "source": [
    "y_actual=train_df.loc[len(train_df)-forecast5.shape[0]:,'Average_Users']\n",
    "y_pred=[float(i) for i in y_pred_future]\n",
    "y_actual=[i for i in y_actual.values]\n",
    "df5 = pd.DataFrame(list(zip(y_pred, y_actual)),columns =['Predicted', 'Actual'])\n",
    "\n",
    "print('MAPE for BiLSTM = ',mape(df5['Actual'], df5['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d311826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for BiLSTM =  14801.56006785671\n"
     ]
    }
   ],
   "source": [
    "print('MSE for BiLSTM = ',mse(df5['Actual'], df5['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43f23c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN\n",
    "sc = MinMaxScaler()\n",
    "scaler=sc.fit(train_df[['Average_Users']])  #\n",
    "scaled_data6 = scaler.transform(train_df[['Average_Users']]) \n",
    "X6,Y6=create_data(1, 2, scaled_data6)\n",
    "x_tr6,y_tr6,x_val6,y_val6=train_test(0.90,X6,Y6)\n",
    "model6 = Sequential()\n",
    "model6.add(Conv1D(filters=128, kernel_size=1, activation='relu', input_shape=(x_tr6.shape[1],x_tr6.shape[2])))\n",
    "model6.add(MaxPooling1D(pool_size=2))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(32,activation='relu'))\n",
    "model6.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5469366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "31/31 [==============================] - 2s 14ms/step - loss: 0.0343 - val_loss: 0.0088\n",
      "Epoch 2/30\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0063 - val_loss: 0.0097\n"
     ]
    }
   ],
   "source": [
    "model_compile(model6,x_tr6,y_tr6,x_val6,y_val6,30,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e705e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "forecast6=model6.predict(x_val6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81f2121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b27c44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_future=sc.inverse_transform(forecast6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0688994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE for CNN =  5.978940617115489\n"
     ]
    }
   ],
   "source": [
    "y_actual=train_df.loc[len(train_df)-forecast6.shape[0]:,'Average_Users']\n",
    "y_pred=[float(i) for i in y_pred_future]\n",
    "y_actual=[i for i in y_actual.values]\n",
    "df6 = pd.DataFrame(list(zip(y_pred, y_actual)),columns =['Predicted', 'Actual'])\n",
    "\n",
    "print('MAPE for CNN = ',mape(df6['Actual'], df6['Predicted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0561376e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for CNN =  15128.013928574515\n"
     ]
    }
   ],
   "source": [
    "print('MSE for CNN = ',mse(df6['Actual'], df6['Predicted']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
